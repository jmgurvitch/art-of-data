# Designing Experiments

## Review
1. What is the difference between **independent** and **dependent** variables?

     The independent variable is the variable the experimenter manipulates or changes, and is assumed to have a direct effect on the dependent variable. The dependent variable is the variable being tested and measured in an experiment, and is, theoretically, affected by changes in the independent variable.

2. What is the difference between a **null** and **alternative** hypothesis?

     A **null** hypothesis is a statement about the population that either is believed to be true or is used to put forth an argument unless it can be shown to be incorrect beyond a reasonable doubt. An **alternative** hypothesis is a claim about the population that is contradictory to the null hypothesis and what we conclude when we reject the null hypothesis.

3. How/why can experimental studies show causation?

     If we can confirm with a high degree of certainty that changes of an independent variable change a dependent variable, experimental studies can show causation. Without rigorous verification, it's just correlation.

## Running Experiments
1. How/why can experimental studies show causation?

     Answered above. 

2. How might sampling bias affect the results of an experiment?

     

3. What might go wrong while conducting an experiment?

     Sampling bias is a bias in which a sample is collected in such a way that some members of the intended population have a lower or higher sampling probability than others. It results in a biased sample of a population in which all individuals, or instances, were not equally likely to have been selected, meaning that the conditions of the experiment could be misrepresented by the results.

## Designing an Experiment
1. Put these steps in the correct order:
     - Ask a precise question
     - Identify independent and dependent variables
     - Identify sample frame
     - Obtain sample to include in experiment
     - Identify population
     - Do background research
     - Conduct treatments on **control** and **experimental** groups
     - Choose sampling method
     - Identify **treatments**
     - Identify null and alternative hypotheses
2. What are some examples of how an experiment can go wrong? Refer to specific steps from the list above.
3. How might an error affect the trustworthiness of a study? How much *should* an error affect the trustworthiness of a study?
4. What might a scientist do to prevent such errors?
5. What does it mean to **double blind** a study?
